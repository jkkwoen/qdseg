"""
Cellulus í•™ìŠµ ëª¨ë“ˆ

ê³µì‹ Cellulus ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ ë¹„ì§€ë„ í•™ìŠµ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ í•™ìŠµ.

ì‚¬ìš©ë²•:
    from grain_analyzer.training import CellulusTrainer, TrainingConfig
    
    config = TrainingConfig(num_epochs=10000, batch_size=16)
    trainer = CellulusTrainer(config)
    images = load_afm_data(config.data_dir)
    zarr_path = trainer.prepare_data(images, for_official=True)
    checkpoint_path = trainer.train_official(zarr_path)
"""

import os
import sys
import argparse
import warnings
import platform
import multiprocessing
from pathlib import Path
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, field
import numpy as np

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    warnings.warn("python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install python-dotenv'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.", ImportWarning)
    pass


# ============================================================
# ì„¤ì • í´ë˜ìŠ¤
# ============================================================

@dataclass
class TrainingConfig:
    """í•™ìŠµ ì„¤ì •"""
    model_type: str = "cellulus"
    use_official: bool = True  # ê³µì‹ Cellulus ì‚¬ìš© ì—¬ë¶€
    num_epochs: int = 10000
    batch_size: int = 4
    learning_rate: float = 1e-4
    patch_size: int = 128
    crop_size: int = 252  # ê³µì‹ Cellulusìš© crop í¬ê¸°
    num_embeddings: int = 8
    num_fmaps: int = 32
    fmap_inc_factor: int = 3  # ê³µì‹ Cellulusìš©
    checkpoint_interval: int = 1000
    log_interval: int = 100
    
    # ê³µì‹ Cellulus ì„¤ì •
    elastic_deform: bool = True
    control_point_spacing: int = 64
    control_point_jitter: float = 2.0
    save_best_model_every: int = 100
    
    # ê²½ë¡œ
    data_dir: Optional[Path] = None
    output_dir: Optional[Path] = None
    
    # GPU ì„¤ì •
    use_gpu: bool = True
    device: Optional[str] = None
    
    # í•˜ë“œì›¨ì–´ ìµœì í™” ì„¤ì •
    num_workers: int = -1  # -1ì´ë©´ ìë™ ê°ì§€
    prefetch_factor: int = 2
    pin_memory: bool = True
    
    # CUDA ìµœì í™” ì„¤ì •
    use_amp: bool = True  # Automatic Mixed Precision
    cudnn_benchmark: bool = True  # cuDNN ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ
    compile_model: bool = False  # torch.compile (PyTorch 2.0+)
    
    def __post_init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ê²½ë¡œ ì½ê¸°
        if self.data_dir is None:
            env_data_dir = os.getenv('QDSEG_DATA_DIR')
            if env_data_dir:
                self.data_dir = Path(env_data_dir)
            else:
                # ê¸°ë³¸ê°’: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
                project_root = Path(__file__).parent.parent.parent
                self.data_dir = project_root / "tests" / "input_data" / "xqd"
        
        if self.output_dir is None:
            env_output_dir = os.getenv('QDSEG_OUTPUT_DIR')
            if env_output_dir:
                self.output_dir = Path(env_output_dir) / self.model_type
            else:
                # ê¸°ë³¸ê°’: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
                project_root = Path(__file__).parent.parent.parent
                self.output_dir = project_root / "tests" / "model_data" / self.model_type
        
        self.data_dir = Path(self.data_dir)
        self.output_dir = Path(self.output_dir)
        
        # num_workers ìë™ ì„¤ì •
        if self.num_workers < 0:
            cpu_count = os.cpu_count() or 4
            # CPU ì½”ì–´ì˜ ì ˆë°˜ ì •ë„ ì‚¬ìš© (ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì™€ GPU ì—°ì‚° ì—¬ìœ )
            self.num_workers = min(cpu_count // 2, 12)


# ============================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================

def get_hardware_info() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ í•˜ë“œì›¨ì–´ ì •ë³´ ìˆ˜ì§‘"""
    import torch
    
    info = {
        'platform': platform.platform(),
        'processor': platform.processor(),
        'cpu_count': os.cpu_count(),
        'python_version': platform.python_version(),
        'torch_version': torch.__version__,
    }
    
    # ë©”ëª¨ë¦¬ ì •ë³´ (macOS)
    try:
        import subprocess
        result = subprocess.run(
            ['sysctl', '-n', 'hw.memsize'], 
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            mem_bytes = int(result.stdout.strip())
            info['memory_gb'] = mem_bytes / (1024 ** 3)
    except Exception:
        info['memory_gb'] = None
    
    # GPU ì •ë³´
    if torch.cuda.is_available():
        info['gpu_type'] = 'cuda'
        info['gpu_name'] = torch.cuda.get_device_name(0)
        info['gpu_memory_gb'] = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        info['gpu_type'] = 'mps'
        info['gpu_name'] = 'Apple Silicon GPU'
        # MPSëŠ” í†µí•© ë©”ëª¨ë¦¬ ì‚¬ìš©
        info['gpu_memory_gb'] = info.get('memory_gb', 'Unified Memory')
    else:
        info['gpu_type'] = 'cpu'
        info['gpu_name'] = None
        info['gpu_memory_gb'] = None
    
    return info


def print_hardware_info():
    """í•˜ë“œì›¨ì–´ ì •ë³´ ì¶œë ¥"""
    info = get_hardware_info()
    
    print("\nğŸ’» í•˜ë“œì›¨ì–´ ì •ë³´:")
    print(f"   ì‹œìŠ¤í…œ: {info['platform']}")
    print(f"   í”„ë¡œì„¸ì„œ: {info['processor']}")
    print(f"   CPU ì½”ì–´: {info['cpu_count']}ê°œ")
    if info.get('memory_gb'):
        print(f"   ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬: {info['memory_gb']:.1f} GB")
    print(f"   Python: {info['python_version']}")
    print(f"   PyTorch: {info['torch_version']}")
    
    if info['gpu_type'] == 'cuda':
        print(f"   GPU: {info['gpu_name']} ({info['gpu_memory_gb']:.1f} GB)")
    elif info['gpu_type'] == 'mps':
        print(f"   GPU: {info['gpu_name']} (í†µí•© ë©”ëª¨ë¦¬)")
    else:
        print("   GPU: ì‚¬ìš© ë¶ˆê°€")
    
    return info


def get_device(use_gpu: bool = True) -> "torch.device":
    """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
    import torch
    
    if not use_gpu:
        print("   âš ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰")
        return torch.device('cpu')
    
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"   âœ“ CUDA GPU ì‚¬ìš©: {torch.cuda.get_device_name(0)}")
        return device
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device('mps')
        print("   âœ“ Apple Silicon MPS ê°€ì† ì‚¬ìš©")
        return device
    
    print("   âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    return torch.device('cpu')


def setup_environment(config: Optional[TrainingConfig] = None):
    """í™˜ê²½ ì„¤ì • - CUDA/MPS ìµœì í™”"""
    import torch
    
    # macOSì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ë²• ì„¤ì • (fork ëŒ€ì‹  spawn ì‚¬ìš©)
    if platform.system() == 'Darwin':
        try:
            multiprocessing.set_start_method('spawn', force=True)
        except RuntimeError:
            pass  # ì´ë¯¸ ì„¤ì •ëœ ê²½ìš°
    
    # ============================================================
    # CUDA ìµœì í™”
    # ============================================================
    if torch.cuda.is_available():
        # cuDNN ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ - ì…ë ¥ í¬ê¸°ê°€ ì¼ì •í•  ë•Œ ìµœì  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
        if config is None or config.cudnn_benchmark:
            torch.backends.cudnn.benchmark = True
            print("   âœ“ cuDNN benchmark ëª¨ë“œ í™œì„±í™”")
        
        # cuDNN deterministic ëª¨ë“œ (ì¬í˜„ì„± í•„ìš”ì‹œ)
        # torch.backends.cudnn.deterministic = True
        
        # TF32 í™œì„±í™” (Ampere ì´ìƒ GPUì—ì„œ ì„±ëŠ¥ í–¥ìƒ)
        if hasattr(torch.backends.cuda, 'matmul'):
            torch.backends.cuda.matmul.allow_tf32 = True
        if hasattr(torch.backends.cudnn, 'allow_tf32'):
            torch.backends.cudnn.allow_tf32 = True
        
        # CUDA ë©”ëª¨ë¦¬ ê´€ë¦¬
        if os.environ.get('PYTORCH_CUDA_ALLOC_CONF') is None:
            # ë©”ëª¨ë¦¬ ë¶„í•  ìµœì í™”
            os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
    
    # ============================================================
    # MPS ìµœì í™” (Apple Silicon)
    # ============================================================
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        # MPS ë©”ëª¨ë¦¬ ìµœì í™” - í†µí•© ë©”ëª¨ë¦¬ ìµœëŒ€ í™œìš©
        if os.environ.get('PYTORCH_MPS_HIGH_WATERMARK_RATIO') is None:
            os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.9'  # 90%ê¹Œì§€ ì‚¬ìš©
        if os.environ.get('PYTORCH_MPS_LOW_WATERMARK_RATIO') is None:
            os.environ['PYTORCH_MPS_LOW_WATERMARK_RATIO'] = '0.0'
        
        # MPS ì—°ì‚° ìµœì í™”
        if os.environ.get('PYTORCH_ENABLE_MPS_FALLBACK') is None:
            os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'  # ë¯¸ì§€ì› ì—°ì‚°ì€ CPUë¡œ í´ë°±
    
    # ê²½ê³  ìˆ¨ê¹€
    warnings.filterwarnings('ignore', category=DeprecationWarning)
    warnings.filterwarnings('ignore', message='.*MPS.*')
    warnings.filterwarnings('ignore', message='.*beta.*')


def load_afm_data(data_dir: Path, target_size: int = 512) -> List[np.ndarray]:
    """AFM XQD íŒŒì¼ë“¤ ë¡œë“œ
    
    Args:
        data_dir: XQD íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        target_size: ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸° (ì •ì‚¬ê°í˜•, ê¸°ë³¸ê°’ 512)
    """
    from grain_analyzer import AFMData
    from skimage.transform import resize
    
    xqd_files = sorted(data_dir.glob("*.xqd"))
    
    if not xqd_files:
        raise FileNotFoundError(f"XQD íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
    
    print(f"\nğŸ“‚ {len(xqd_files)}ê°œì˜ XQD íŒŒì¼ ë°œê²¬")
    
    images = []
    for xqd_file in xqd_files:
        try:
            data = AFMData(str(xqd_file))
            data.first_correction().second_correction().third_correction()
            data.flat_correction("line_by_line").baseline_correction("min_to_zero")
            
            height = data.get_data()
            original_shape = height.shape
            
            # Resize if needed
            if height.shape[0] != target_size or height.shape[1] != target_size:
                height = resize(height, (target_size, target_size), 
                               preserve_range=True, anti_aliasing=True)
            
            # Normalize to [0, 1]
            pmin, pmax = np.percentile(height, [1, 99])
            if pmax - pmin > 1e-10:
                height_norm = np.clip((height - pmin) / (pmax - pmin), 0, 1)
            else:
                height_norm = np.zeros_like(height)
            
            images.append(height_norm.astype(np.float32))
            if original_shape != (target_size, target_size):
                print(f"   âœ“ {xqd_file.name}: {original_shape} â†’ ({target_size}, {target_size})")
            else:
                print(f"   âœ“ {xqd_file.name}: {height.shape}")
        except Exception as e:
            print(f"   âŒ {xqd_file.name}: {e}")
    
    return images


# ============================================================
# Cellulus í•™ìŠµ
# ============================================================

class CellulusTrainer:
    """Cellulus ëª¨ë¸ í•™ìŠµê¸° (ê³µì‹ ë° ê°„ì†Œí™” ëª¨ë¸ ì§€ì›)"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.device = None
        self.model = None
        self.optimizer = None
        self.scaler = None  # AMP GradScaler
        self.use_amp = False  # AMP ì‚¬ìš© ì—¬ë¶€
        
    def prepare_data(self, images: List[np.ndarray], for_official: bool = False) -> Path:
        """ë°ì´í„°ë¥¼ Zarr í˜•ì‹ìœ¼ë¡œ ì¤€ë¹„
        
        Args:
            images: í•™ìŠµ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            for_official: Trueì´ë©´ ê³µì‹ Cellulus í˜•ì‹ (N, 1, H, W), Falseì´ë©´ (N, H, W)
        """
        import zarr
        
        zarr_path = self.config.output_dir / "afm_grains.zarr"
        
        print(f"\nğŸ“¦ Zarr ë°ì´í„°ì…‹ ìƒì„±: {zarr_path}")
        
        stacked = np.stack(images, axis=0).astype(np.float32)
        
        # ê³µì‹ CellulusëŠ” (N, 1, H, W) í˜•ì‹ í•„ìš”
        if for_official:
            stacked = stacked[:, np.newaxis, :, :]  # (N, H, W) -> (N, 1, H, W)
        
        n_train = max(1, len(images) - 2)
        train_data = stacked[:n_train]
        test_data = stacked[n_train:] if n_train < len(images) else stacked[-1:]
        
        root = zarr.open_group(str(zarr_path), mode='w')
        
        try:
            train_group = root.create_group('train')
            test_group = root.create_group('test')
            chunk_size = (1, 1, 256, 256) if for_official else (1, 256, 256)
            train_group.create_array('raw', data=train_data, chunks=chunk_size)
            test_group.create_array('raw', data=test_data, chunks=chunk_size)
            
            # ê³µì‹ Cellulusìš© ë©”íƒ€ë°ì´í„°
            if for_official:
                root['train/raw'].attrs['resolution'] = (1, 1)
                root['train/raw'].attrs['axis_names'] = ('s', 'c', 'y', 'x')
                root['test/raw'].attrs['resolution'] = (1, 1)
                root['test/raw'].attrs['axis_names'] = ('s', 'c', 'y', 'x')
        except (TypeError, AttributeError):
            root['train/raw'] = train_data
            root['test/raw'] = test_data
            if for_official:
                root['train/raw'].attrs['resolution'] = (1, 1)
                root['train/raw'].attrs['axis_names'] = ('s', 'c', 'y', 'x')
        
        print(f"   âœ“ train/raw: {train_data.shape}")
        print(f"   âœ“ test/raw: {test_data.shape}")
        
        return zarr_path
    
    def train_official(self, zarr_path: Path) -> Path:
        """ê³µì‹ Cellulus í•™ìŠµ
        
        cellulus.cli.train_experimentë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.
        
        Returns:
            checkpoint_path: í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        """
        import os
        import torch
        
        try:
            from cellulus.cli import ExperimentConfig, train_experiment
        except ImportError:
            raise ImportError(
                "ê³µì‹ Cellulus í•™ìŠµì„ ìœ„í•´ cellulus íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤:\n"
                "pip install git+https://github.com/funkelab/cellulus.git"
            )
        
        print("\nğŸ”· ê³µì‹ Cellulus í•™ìŠµ ì‹œì‘")
        
        # ë””ë°”ì´ìŠ¤ ê²°ì •
        device = self.config.device
        if device is None:
            if torch.cuda.is_available():
                device = "cuda:0"
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                device = "mps"
            else:
                device = "cpu"
        
        # zarr ê²½ë¡œ (ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜)
        zarr_rel = os.path.relpath(str(zarr_path), str(self.config.output_dir))
        
        # ì„¤ì • ìƒì„±
        config = {
            'normalization_factor': 1.0,
            'model_config': {
                'num_fmaps': self.config.num_fmaps,
                'fmap_inc_factor': self.config.fmap_inc_factor,
                'downsampling_factors': [[2, 2]],
            },
            'train_config': {
                'crop_size': [self.config.crop_size, self.config.crop_size],
                'batch_size': self.config.batch_size,
                'max_iterations': self.config.num_epochs,
                'initial_learning_rate': self.config.learning_rate,
                'elastic_deform': self.config.elastic_deform,
                'control_point_spacing': self.config.control_point_spacing,
                'control_point_jitter': self.config.control_point_jitter,
                'save_model_every': self.config.checkpoint_interval,
                'save_best_model_every': self.config.save_best_model_every,
                'save_snapshot_every': self.config.checkpoint_interval,
                'num_workers': self.config.num_workers if self.config.num_workers > 0 else 4,
                'device': device,
                'train_data_config': {
                    'container_path': zarr_rel,
                    'dataset_name': 'train/raw',
                },
            },
        }
        
        print(f"\nğŸ“‹ ê³µì‹ Cellulus ì„¤ì •:")
        print(f"   num_fmaps: {self.config.num_fmaps}")
        print(f"   fmap_inc_factor: {self.config.fmap_inc_factor}")
        print(f"   crop_size: {self.config.crop_size}")
        print(f"   batch_size: {self.config.batch_size}")
        print(f"   max_iterations: {self.config.num_epochs}")
        print(f"   learning_rate: {self.config.learning_rate}")
        print(f"   device: {device}")
        
        # ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½ (ëª¨ë¸ ì €ì¥ ê²½ë¡œ ê¸°ì¤€)
        original_cwd = os.getcwd()
        os.chdir(str(self.config.output_dir))
        
        try:
            print(f"\nğŸš€ í•™ìŠµ ì‹œì‘ (ì‘ì—… ë””ë ‰í† ë¦¬: {self.config.output_dir})\n")
            
            # ExperimentConfig ìƒì„± ë° í•™ìŠµ ì‹¤í–‰
            experiment_config = ExperimentConfig(**config)
            train_experiment(experiment_config)
            
        finally:
            os.chdir(original_cwd)
        
        # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        checkpoint_path = self.config.output_dir / "models" / "best_loss.pth"
        
        if checkpoint_path.exists():
            print(f"\nâœ… í•™ìŠµ ì™„ë£Œ: {checkpoint_path}")
        else:
            # ë‹¤ë¥¸ ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
            models_dir = self.config.output_dir / "models"
            if models_dir.exists():
                pth_files = list(models_dir.glob("*.pth"))
                if pth_files:
                    checkpoint_path = pth_files[0]
                    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ: {checkpoint_path}")
        
        return checkpoint_path
    
    def build_model(self):
        """ëª¨ë¸ êµ¬ì¶•"""
        import torch
        import torch.nn as nn
        
        class SimpleUNet(nn.Module):
            """ê°„ë‹¨í•œ U-Net ê¸°ë°˜ ì„ë² ë”© ë„¤íŠ¸ì›Œí¬"""
            
            def __init__(self, in_channels=1, num_embeddings=8, num_fmaps=32):
                super().__init__()
                
                self.enc1 = self._block(in_channels, num_fmaps)
                self.enc2 = self._block(num_fmaps, num_fmaps * 2)
                self.enc3 = self._block(num_fmaps * 2, num_fmaps * 4)
                
                self.dec2 = self._block(num_fmaps * 4 + num_fmaps * 2, num_fmaps * 2)
                self.dec1 = self._block(num_fmaps * 2 + num_fmaps, num_fmaps)
                
                self.out = nn.Conv2d(num_fmaps, num_embeddings, 1)
                
                self.pool = nn.MaxPool2d(2)
                self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            
            def _block(self, in_ch, out_ch):
                return nn.Sequential(
                    nn.Conv2d(in_ch, out_ch, 3, padding=1),
                    nn.BatchNorm2d(out_ch),
                    nn.ReLU(inplace=True),
                    nn.Conv2d(out_ch, out_ch, 3, padding=1),
                    nn.BatchNorm2d(out_ch),
                    nn.ReLU(inplace=True),
                )
            
            def forward(self, x):
                e1 = self.enc1(x)
                e2 = self.enc2(self.pool(e1))
                e3 = self.enc3(self.pool(e2))
                
                d2 = self.dec2(torch.cat([self.up(e3), e2], dim=1))
                d1 = self.dec1(torch.cat([self.up(d2), e1], dim=1))
                
                return self.out(d1)
        
        self.model = SimpleUNet(
            num_embeddings=self.config.num_embeddings,
            num_fmaps=self.config.num_fmaps,
        ).to(self.device)
        
        self.optimizer = torch.optim.Adam(
            self.model.parameters(), 
            lr=self.config.learning_rate
        )
        
        return self.model
    
    def contrastive_loss(self, embeddings, temperature=0.1):
        """Object-centric contrastive loss"""
        import torch
        import torch.nn.functional as F
        
        b, c, h, w = embeddings.shape
        device = embeddings.device
        
        embeddings = F.normalize(embeddings, dim=1)
        
        num_anchors = min(256, h * w)
        indices = torch.randperm(h * w, device=device)[:num_anchors]
        
        embeddings_flat = embeddings.view(b, c, -1)
        anchors = embeddings_flat[:, :, indices]
        
        similarity = torch.bmm(anchors.transpose(1, 2), embeddings_flat) / temperature
        
        anchor_y = indices // w
        anchor_x = indices % w
        all_y = torch.arange(h, device=device).view(-1, 1).expand(h, w).reshape(-1)
        all_x = torch.arange(w, device=device).view(1, -1).expand(h, w).reshape(-1)
        
        dist = ((anchor_y.view(-1, 1) - all_y.view(1, -1)) ** 2 + 
                (anchor_x.view(-1, 1) - all_x.view(1, -1)) ** 2).float().sqrt()
        
        positive_mask = (dist < 5).float()
        negative_mask = (dist > 20).float()
        
        exp_sim = torch.exp(similarity)
        
        positive_sim = (exp_sim * positive_mask.unsqueeze(0)).sum(dim=-1)
        negative_sim = (exp_sim * negative_mask.unsqueeze(0)).sum(dim=-1)
        
        loss = -torch.log(positive_sim / (positive_sim + negative_sim + 1e-10) + 1e-10)
        
        return loss.mean()
    
    def train(self, zarr_path: Path):
        """ëª¨ë¸ í•™ìŠµ"""
        import torch
        from torch.utils.data import Dataset, DataLoader
        import zarr
        from tqdm import tqdm
        
        # ë°ì´í„°ì…‹ í´ë˜ìŠ¤
        class AFMDataset(Dataset):
            def __init__(self, zarr_path, dataset_name='train/raw', patch_size=128):
                root = zarr.open_group(str(zarr_path), mode='r')
                self.data = np.array(root[dataset_name][:])
                self.patch_size = patch_size
                
            def __len__(self):
                return len(self.data) * 16
            
            def __getitem__(self, idx):
                img_idx = idx % len(self.data)
                img = self.data[img_idx]
                
                h, w = img.shape
                y = np.random.randint(0, max(1, h - self.patch_size))
                x = np.random.randint(0, max(1, w - self.patch_size))
                
                patch = img[y:y+self.patch_size, x:x+self.patch_size]
                
                if patch.shape[0] < self.patch_size or patch.shape[1] < self.patch_size:
                    padded = np.zeros((self.patch_size, self.patch_size), dtype=np.float32)
                    padded[:patch.shape[0], :patch.shape[1]] = patch
                    patch = padded
                
                return torch.from_numpy(patch).unsqueeze(0)
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = get_device(self.config.use_gpu)
        
        # ============================================================
        # AMP (Automatic Mixed Precision) ì„¤ì •
        # ============================================================
        self.use_amp = False
        self.scaler = None
        
        if self.config.use_amp:
            if self.device.type == 'cuda':
                # CUDA AMP - FP16 ì‚¬ìš©
                self.use_amp = True
                self.scaler = torch.cuda.amp.GradScaler()
                print("   âœ“ CUDA AMP (FP16) í™œì„±í™”")
            elif self.device.type == 'mps':
                # MPSì—ì„œëŠ” AMP ì œí•œì  ì§€ì›
                # PyTorch 2.0+ ì—ì„œ ì¼ë¶€ ì§€ì›
                try:
                    # MPSì—ì„œ autocast í…ŒìŠ¤íŠ¸
                    with torch.autocast(device_type='mps', dtype=torch.float16):
                        pass
                    self.use_amp = True
                    print("   âœ“ MPS AMP í™œì„±í™”")
                except Exception:
                    self.use_amp = False
                    print("   âš ï¸ MPS AMP ë¯¸ì§€ì› - FP32 ì‚¬ìš©")
        
        # ëª¨ë¸ êµ¬ì¶•
        self.build_model()
        
        # ============================================================
        # torch.compile (PyTorch 2.0+) - ì¶”ê°€ ìµœì í™”
        # ============================================================
        if self.config.compile_model and hasattr(torch, 'compile'):
            try:
                self.model = torch.compile(self.model)
                print("   âœ“ torch.compile ì ìš©")
            except Exception as e:
                print(f"   âš ï¸ torch.compile ì‹¤íŒ¨: {e}")
        
        # ë°ì´í„°ë¡œë” - ë©€í‹°ì½”ì–´ CPU í™œìš©
        dataset = AFMDataset(zarr_path, patch_size=self.config.patch_size)
        
        # ë””ë°”ì´ìŠ¤ì— ë”°ë¥¸ ìµœì í™” ì„¤ì •
        num_workers = self.config.num_workers
        pin_memory = self.config.pin_memory
        prefetch_factor = self.config.prefetch_factor
        persistent_workers = num_workers > 0
        
        # MPSì—ì„œëŠ” pin_memoryê°€ íš¨ê³¼ ì—†ìŒ (í†µí•© ë©”ëª¨ë¦¬)
        if self.device.type == 'mps':
            pin_memory = False
        
        print(f"\nâš¡ DataLoader ì„¤ì •:")
        print(f"   num_workers: {num_workers}")
        print(f"   prefetch_factor: {prefetch_factor}")
        print(f"   pin_memory: {pin_memory}")
        print(f"   persistent_workers: {persistent_workers}")
        
        dataloader_kwargs = {
            'batch_size': self.config.batch_size,
            'shuffle': True,
            'num_workers': num_workers,
            'pin_memory': pin_memory,
        }
        
        # num_workers > 0ì¼ ë•Œë§Œ ì¶”ê°€ ì˜µì…˜ ì ìš©
        if num_workers > 0:
            dataloader_kwargs['prefetch_factor'] = prefetch_factor
            dataloader_kwargs['persistent_workers'] = persistent_workers
        
        dataloader = DataLoader(dataset, **dataloader_kwargs)
        
        print(f"\nğŸš€ í•™ìŠµ ì‹œì‘: {self.config.num_epochs} epochs, batch_size={self.config.batch_size}\n")
        
        best_loss = float('inf')
        checkpoint_path = self.config.output_dir / 'best_loss.pth'
        
        # tqdm ì§„í–‰ í‘œì‹œì¤„
        epoch_pbar = tqdm(
            range(self.config.num_epochs),
            desc="Training",
            unit="epoch",
            ncols=100,
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
        )
        
        for epoch in epoch_pbar:
            self.model.train()
            total_loss = 0
            
            # ë°°ì¹˜ë³„ ì§„í–‰ í‘œì‹œ (ì—í­ ë‚´)
            batch_pbar = tqdm(
                dataloader,
                desc=f"  Epoch {epoch+1}",
                leave=False,
                ncols=80,
                bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt}'
            )
            
            for batch in batch_pbar:
                batch = batch.to(self.device, non_blocking=True)
                
                self.optimizer.zero_grad(set_to_none=True)  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
                
                # AMP ì ìš©
                if self.use_amp and self.device.type == 'cuda':
                    with torch.cuda.amp.autocast():
                        embeddings = self.model(batch)
                        loss = self.contrastive_loss(embeddings)
                    self.scaler.scale(loss).backward()
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                elif self.use_amp and self.device.type == 'mps':
                    with torch.autocast(device_type='mps', dtype=torch.float16):
                        embeddings = self.model(batch)
                        loss = self.contrastive_loss(embeddings)
                    loss.backward()
                    self.optimizer.step()
                else:
                    embeddings = self.model(batch)
                    loss = self.contrastive_loss(embeddings)
                    loss.backward()
                    self.optimizer.step()
                
                total_loss += loss.item()
            
            avg_loss = total_loss / len(dataloader)
            
            # ì§„í–‰ í‘œì‹œì¤„ ì—…ë°ì´íŠ¸
            epoch_pbar.set_postfix({
                'loss': f'{avg_loss:.4f}',
                'best': f'{best_loss:.4f}'
            })
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if avg_loss < best_loss:
                best_loss = avg_loss
                torch.save({
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'epoch': epoch,
                    'loss': avg_loss,
                    'config': {
                        'num_embeddings': self.config.num_embeddings,
                        'num_fmaps': self.config.num_fmaps,
                    }
                }, checkpoint_path)
                # ì§„í–‰ í‘œì‹œì¤„ ì—…ë°ì´íŠ¸
                epoch_pbar.set_postfix({
                    'loss': f'{avg_loss:.4f}',
                    'best': f'{best_loss:.4f}',
                    'saved': 'âœ“'
                })
            
            # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸
            if (epoch + 1) % self.config.checkpoint_interval == 0:
                periodic_path = self.config.output_dir / f'checkpoint_epoch_{epoch+1}.pth'
                torch.save({
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'epoch': epoch,
                    'loss': avg_loss,
                }, periodic_path)
                tqdm.write(f"   ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {periodic_path.name}")
        
        epoch_pbar.close()
        print(f"\nâœ“ í•™ìŠµ ì™„ë£Œ! Best loss: {best_loss:.4f}")
        print(f"âœ“ ëª¨ë¸ ì €ì¥ë¨: {checkpoint_path}")
        
        return checkpoint_path


# ============================================================
# í–¥í›„ í™•ì¥ìš© Trainer í´ë˜ìŠ¤ë“¤
# ============================================================

class StarDistTrainer:
    """StarDist ëª¨ë¸ í•™ìŠµê¸° (í–¥í›„ êµ¬í˜„)"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
    
    def train(self, images: List[np.ndarray], labels: List[np.ndarray]):
        """
        StarDist í•™ìŠµ (ë¼ë²¨ í•„ìš”)
        
        TODO: StarDist ì»¤ìŠ¤í…€ í•™ìŠµ êµ¬í˜„
        """
        raise NotImplementedError(
            "StarDist ì»¤ìŠ¤í…€ í•™ìŠµì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "ì°¸ê³ : https://github.com/stardist/stardist"
        )


class CellposeTrainer:
    """Cellpose ëª¨ë¸ í•™ìŠµê¸° (í–¥í›„ êµ¬í˜„)"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
    
    def train(self, images: List[np.ndarray], labels: List[np.ndarray]):
        """
        Cellpose í•™ìŠµ (ë¼ë²¨ í•„ìš”)
        
        TODO: Cellpose ì»¤ìŠ¤í…€ í•™ìŠµ êµ¬í˜„
        """
        raise NotImplementedError(
            "Cellpose ì»¤ìŠ¤í…€ í•™ìŠµì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "ì°¸ê³ : https://github.com/MouseLand/cellpose"
        )


# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def get_trainer(config: TrainingConfig):
    """ì„¤ì •ì— ë§ëŠ” Trainer ë°˜í™˜"""
    trainers = {
        'cellulus': CellulusTrainer,
        'stardist': StarDistTrainer,
        'cellpose': CellposeTrainer,
    }
    
    if config.model_type not in trainers:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {config.model_type}\n"
                        f"ì§€ì› ëª¨ë¸: {list(trainers.keys())}")
    
    return trainers[config.model_type](config)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='Grain Analyzer ëª¨ë¸ í•™ìŠµ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ê¸°ë³¸ Cellulus í•™ìŠµ
  python train_model.py
  
  # ì—í­ ìˆ˜ ì§€ì •
  python train_model.py --epochs 5000
  
  # ì»¤ìŠ¤í…€ ê²½ë¡œ
  python train_model.py --data-dir ./my_data --output-dir ./my_models
  
  # ë°°ì¹˜ í¬ê¸° ë° í•™ìŠµë¥  ì¡°ì •
  python train_model.py --batch-size 8 --lr 0.0005
"""
    )
    
    # ëª¨ë¸ ì„¤ì •
    parser.add_argument('--model', type=str, default='cellulus',
                        choices=['cellulus', 'stardist', 'cellpose'],
                        help='í•™ìŠµí•  ëª¨ë¸ íƒ€ì… (ê¸°ë³¸: cellulus)')
    parser.add_argument('--official', action='store_true', default=True,
                        help='ê³µì‹ Cellulus ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (ê¸°ë³¸: True)')
    parser.add_argument('--simple', action='store_true',
                        help='ê°„ì†Œí™” ëª¨ë¸ ì‚¬ìš© (ê³µì‹ Cellulus ëŒ€ì‹ )')
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    parser.add_argument('--epochs', type=int, default=10000,
                        help='í•™ìŠµ ì—í­/ë°˜ë³µ ìˆ˜ (ê¸°ë³¸: 10000)')
    parser.add_argument('--batch-size', type=int, default=16,
                        help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 16, ê³µì‹ Cellulus ê¶Œì¥)')
    parser.add_argument('--lr', type=float, default=4e-5,
                        help='í•™ìŠµë¥  (ê¸°ë³¸: 4e-5, ê³µì‹ Cellulus ê¶Œì¥)')
    parser.add_argument('--patch-size', type=int, default=128,
                        help='í•™ìŠµ íŒ¨ì¹˜ í¬ê¸° - ê°„ì†Œí™” ëª¨ë¸ìš© (ê¸°ë³¸: 128)')
    parser.add_argument('--crop-size', type=int, default=252,
                        help='í•™ìŠµ crop í¬ê¸° - ê³µì‹ Cellulusìš© (ê¸°ë³¸: 252)')
    
    # ëª¨ë¸ êµ¬ì¡°
    parser.add_argument('--num-embeddings', type=int, default=8,
                        help='ì„ë² ë”© ì±„ë„ ìˆ˜ - ê°„ì†Œí™” ëª¨ë¸ìš© (ê¸°ë³¸: 8)')
    parser.add_argument('--num-fmaps', type=int, default=24,
                        help='ê¸°ë³¸ íŠ¹ì„± ë§µ ìˆ˜ (ê¸°ë³¸: 24, ê³µì‹ Cellulus ê¶Œì¥)')
    parser.add_argument('--fmap-inc-factor', type=int, default=3,
                        help='ë ˆì´ì–´ë³„ íŠ¹ì„± ë§µ ì¦ê°€ìœ¨ - ê³µì‹ Cellulusìš© (ê¸°ë³¸: 3)')
    
    # ê²½ë¡œ
    parser.add_argument('--data-dir', type=str, default=None,
                        help='í•™ìŠµ ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸: tests/input_data/qd)')
    parser.add_argument('--output-dir', type=str, default=None,
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: tests/model_data/{model})')
    
    # GPU ì„¤ì •
    parser.add_argument('--no-gpu', action='store_true',
                        help='GPU ì‚¬ìš© ë¹„í™œì„±í™”')
    parser.add_argument('--device', type=str, default=None,
                        help='íŠ¹ì • ë””ë°”ì´ìŠ¤ ì§€ì • (cuda, mps, cpu)')
    
    # ì²´í¬í¬ì¸íŠ¸
    parser.add_argument('--checkpoint-interval', type=int, default=1000,
                        help='ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê°„ê²© (ê¸°ë³¸: 1000)')
    parser.add_argument('--log-interval', type=int, default=100,
                        help='ë¡œê·¸ ì¶œë ¥ ê°„ê²© (ê¸°ë³¸: 100)')
    
    # í•˜ë“œì›¨ì–´ ìµœì í™”
    parser.add_argument('--num-workers', type=int, default=-1,
                        help='DataLoader ì›Œì»¤ ìˆ˜ (-1: ìë™, 0: ë¹„í™œì„±í™”)')
    parser.add_argument('--prefetch-factor', type=int, default=2,
                        help='ë¯¸ë¦¬ ë¡œë“œí•  ë°°ì¹˜ ìˆ˜ (ê¸°ë³¸: 2)')
    parser.add_argument('--no-pin-memory', action='store_true',
                        help='pin_memory ë¹„í™œì„±í™”')
    
    # CUDA/GPU ìµœì í™”
    parser.add_argument('--no-amp', action='store_true',
                        help='Automatic Mixed Precision ë¹„í™œì„±í™”')
    parser.add_argument('--no-cudnn-benchmark', action='store_true',
                        help='cuDNN benchmark ëª¨ë“œ ë¹„í™œì„±í™”')
    parser.add_argument('--compile', action='store_true',
                        help='torch.compile ì‚¬ìš© (PyTorch 2.0+)')
    
    args = parser.parse_args()
    
    # --simple ì˜µì…˜ì´ ìˆìœ¼ë©´ ê³µì‹ Cellulus ë¹„í™œì„±í™”
    use_official = not args.simple
    
    # ì„¤ì • ìƒì„±
    config = TrainingConfig(
        model_type=args.model,
        use_official=use_official,
        num_epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.lr,
        patch_size=args.patch_size,
        crop_size=args.crop_size,
        num_embeddings=args.num_embeddings,
        num_fmaps=args.num_fmaps,
        fmap_inc_factor=args.fmap_inc_factor,
        data_dir=Path(args.data_dir) if args.data_dir else None,
        output_dir=Path(args.output_dir) if args.output_dir else None,
        use_gpu=not args.no_gpu,
        device=args.device,
        checkpoint_interval=args.checkpoint_interval,
        log_interval=args.log_interval,
        num_workers=args.num_workers,
        prefetch_factor=args.prefetch_factor,
        pin_memory=not args.no_pin_memory,
        use_amp=not args.no_amp,
        cudnn_benchmark=not args.no_cudnn_benchmark,
        compile_model=args.compile,
    )
    
    # í™˜ê²½ ì„¤ì •
    setup_environment(config)
    
    # í—¤ë” ì¶œë ¥
    print("=" * 70)
    print(f"ğŸ§  Grain Analyzer ëª¨ë¸ í•™ìŠµ: {config.model_type.upper()}")
    print("=" * 70)
    
    # í•˜ë“œì›¨ì–´ ì •ë³´ ì¶œë ¥
    hw_info = print_hardware_info()
    
    print(f"\nğŸ“‹ í•™ìŠµ ì„¤ì •:")
    print(f"   ëª¨ë¸: {config.model_type}")
    print(f"   ê³µì‹ Cellulus: {'âœ“' if config.use_official else 'âœ— (ê°„ì†Œí™” ëª¨ë¸)'}")
    print(f"   ë°˜ë³µ ìˆ˜: {config.num_epochs}")
    print(f"   ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
    print(f"   í•™ìŠµë¥ : {config.learning_rate}")
    if config.use_official:
        print(f"   crop_size: {config.crop_size}")
        print(f"   num_fmaps: {config.num_fmaps}")
        print(f"   fmap_inc_factor: {config.fmap_inc_factor}")
    print(f"   DataLoader ì›Œì»¤: {config.num_workers}")
    print(f"   ë°ì´í„°: {config.data_dir}")
    print(f"   ì¶œë ¥: {config.output_dir}")
    
    # M3 Ultra ìµœì í™” ê¶Œì¥ì‚¬í•­
    if hw_info.get('cpu_count', 0) >= 20 and hw_info.get('memory_gb', 0) >= 64:
        print(f"\nğŸ’¡ ê³ ì„±ëŠ¥ í•˜ë“œì›¨ì–´ ê°ì§€! ê¶Œì¥ ì„¤ì •:")
        print(f"   --batch-size 16 ë˜ëŠ” 32 (í˜„ì¬: {config.batch_size})")
        print(f"   --num-workers 8~12 (í˜„ì¬: {config.num_workers})")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    config.output_dir.mkdir(parents=True, exist_ok=True)
    
    # ë°ì´í„° ë¡œë“œ
    print("\n" + "=" * 70)
    print("1ï¸âƒ£  ë°ì´í„° ë¡œë“œ")
    print("=" * 70)
    
    images = load_afm_data(config.data_dir)
    
    if not images:
        print("âŒ ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 1
    
    # Trainer ìƒì„± ë° í•™ìŠµ
    print("\n" + "=" * 70)
    print(f"2ï¸âƒ£  {config.model_type.upper()} ëª¨ë¸ í•™ìŠµ")
    print("=" * 70)
    
    trainer = get_trainer(config)
    
    if config.model_type == 'cellulus':
        if config.use_official:
            # ê³µì‹ Cellulus í•™ìŠµ
            zarr_path = trainer.prepare_data(images, for_official=True)
            checkpoint_path = trainer.train_official(zarr_path)
        else:
            # ê°„ì†Œí™” ëª¨ë¸ í•™ìŠµ
            zarr_path = trainer.prepare_data(images, for_official=False)
            checkpoint_path = trainer.train(zarr_path)
    else:
        # StarDist, CellposeëŠ” ë¼ë²¨ì´ í•„ìš”
        trainer.train(images, labels=None)
        checkpoint_path = None
    
    # ì™„ë£Œ
    print("\n" + "=" * 70)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    print("=" * 70)
    
    if checkpoint_path and checkpoint_path.exists():
        print(f"\nâœ“ í•™ìŠµëœ ëª¨ë¸: {checkpoint_path}")
        print("\nì‚¬ìš© ë°©ë²•:")
        print("   from grain_analyzer import segment_cellulus")
        print(f"   labels = segment_cellulus(height, checkpoint_path='{checkpoint_path}')")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

