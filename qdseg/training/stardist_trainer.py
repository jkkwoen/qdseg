"""
StarDist Trainer for AFM Grain Images

StarDist ëª¨ë¸ì„ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµì‹œí‚¤ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
ì§€ë„ í•™ìŠµ(Supervised Learning)ì´ë¯€ë¡œ ë ˆì´ë¸”ë§ëœ ë§ˆìŠ¤í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

Requirements:
    - stardist
    - tensorflow
    - numpy
    - labeled masks (from napari, ImageJ, etc.)

Usage:
    from grain_analyzer.training import StarDistTrainer, StarDistConfig
    
    config = StarDistConfig(
        data_dir=Path("./labeled_data"),
        output_dir=Path("./models/stardist_afm"),
        epochs=100,
    )
    trainer = StarDistTrainer(config)
    trainer.train()
"""

from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional, Tuple
import numpy as np


@dataclass
class StarDistConfig:
    """StarDist í•™ìŠµ ì„¤ì •"""
    
    # ë°ì´í„° ê²½ë¡œ
    data_dir: Path = field(default_factory=lambda: Path("./data"))
    output_dir: Path = field(default_factory=lambda: Path("./models/stardist"))
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    epochs: int = 100
    batch_size: int = 4
    learning_rate: float = 1e-4
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„°
    n_rays: int = 32  # StarDistì˜ ray ê°œìˆ˜ (32ê°€ ì¼ë°˜ì )
    grid: Tuple[int, int] = (2, 2)  # ì˜ˆì¸¡ ê·¸ë¦¬ë“œ ìŠ¤ì¼€ì¼
    
    # ì¦ê°•
    use_augmentation: bool = True
    
    # ê²€ì¦
    validation_split: float = 0.1
    
    # ê¸°íƒ€
    model_name: str = "stardist_afm"


class StarDistTrainer:
    """
    StarDist ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤
    
    ì§€ë„ í•™ìŠµì„ ìœ„í•´ ë‹¤ìŒ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤:
    - images/: ì›ë³¸ AFM ì´ë¯¸ì§€ (npy, tiff, png ë“±)
    - masks/: ë ˆì´ë¸” ë§ˆìŠ¤í¬ (ê° ê°ì²´ê°€ ê³ ìœ  ì •ìˆ˜ë¡œ í‘œì‹œ)
    
    Example:
        config = StarDistConfig(
            data_dir=Path("./labeled_data"),
            output_dir=Path("./models/stardist_afm"),
        )
        trainer = StarDistTrainer(config)
        
        # ë°ì´í„° ë¡œë“œ
        images, masks = trainer.load_data()
        
        # í•™ìŠµ
        trainer.train(images, masks)
        
        # ëª¨ë¸ ê²½ë¡œ
        print(f"Model saved to: {trainer.get_model_path()}")
    """
    
    def __init__(self, config: StarDistConfig):
        self.config = config
        self._check_dependencies()
        
    def _check_dependencies(self):
        """í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸"""
        try:
            import stardist
            import tensorflow as tf
        except ImportError as e:
            raise ImportError(
                "StarDist í•™ìŠµì„ ìœ„í•´ì„œëŠ” stardistì™€ tensorflowê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
                "ì„¤ì¹˜: pip install stardist tensorflow\n"
                f"ì˜¤ë¥˜: {e}"
            )
    
    def load_data(self) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """
        í•™ìŠµ ë°ì´í„° ë¡œë“œ
        
        ë°ì´í„° êµ¬ì¡°:
            data_dir/
                images/
                    image_001.npy (ë˜ëŠ” .tiff, .png)
                    image_002.npy
                    ...
                masks/
                    mask_001.npy (ë˜ëŠ” .tiff, .png)
                    mask_002.npy
                    ...
        
        Returns:
            images: ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ê°ê° 2D numpy array)
            masks: ë§ˆìŠ¤í¬ ë¦¬ìŠ¤íŠ¸ (ê°ê° 2D numpy array, int labels)
        """
        from tifffile import imread as tiff_imread
        from skimage.io import imread
        
        images_dir = self.config.data_dir / "images"
        masks_dir = self.config.data_dir / "masks"
        
        if not images_dir.exists() or not masks_dir.exists():
            raise FileNotFoundError(
                f"ë°ì´í„° ë””ë ‰í† ë¦¬ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
                f"í•„ìš”í•œ êµ¬ì¡°:\n"
                f"  {self.config.data_dir}/\n"
                f"    images/\n"
                f"    masks/\n"
            )
        
        images = []
        masks = []
        
        # ì§€ì›í•˜ëŠ” í™•ì¥ì
        extensions = ['*.npy', '*.tiff', '*.tif', '*.png']
        image_files = []
        for ext in extensions:
            image_files.extend(sorted(images_dir.glob(ext)))
        
        print(f"\nğŸ“‚ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬")
        
        for img_path in image_files:
            # ë§¤ì¹­ë˜ëŠ” ë§ˆìŠ¤í¬ ì°¾ê¸°
            mask_path = None
            for ext in ['.npy', '.tiff', '.tif', '.png']:
                candidate = masks_dir / (img_path.stem + ext)
                if candidate.exists():
                    mask_path = candidate
                    break
            
            if mask_path is None:
                print(f"   âš ï¸ {img_path.name}: ë§¤ì¹­ë˜ëŠ” ë§ˆìŠ¤í¬ ì—†ìŒ")
                continue
            
            try:
                # ì´ë¯¸ì§€ ë¡œë“œ
                if img_path.suffix == '.npy':
                    img = np.load(img_path)
                elif img_path.suffix in ['.tiff', '.tif']:
                    img = tiff_imread(img_path)
                else:
                    img = imread(img_path)
                
                # ë§ˆìŠ¤í¬ ë¡œë“œ
                if mask_path.suffix == '.npy':
                    mask = np.load(mask_path)
                elif mask_path.suffix in ['.tiff', '.tif']:
                    mask = tiff_imread(mask_path)
                else:
                    mask = imread(mask_path)
                
                # ì •ê·œí™”
                if img.max() > 1:
                    img = img.astype(np.float32)
                    pmin, pmax = np.percentile(img, [1, 99])
                    img = np.clip((img - pmin) / (pmax - pmin + 1e-10), 0, 1)
                
                # ë§ˆìŠ¤í¬ê°€ ì •ìˆ˜í˜•ì¸ì§€ í™•ì¸
                mask = mask.astype(np.int32)
                
                images.append(img)
                masks.append(mask)
                print(f"   âœ“ {img_path.name}: {img.shape}, {mask.max()} objects")
                
            except Exception as e:
                print(f"   âŒ {img_path.name}: {e}")
        
        if not images:
            raise ValueError("ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"\nâœ“ ì´ {len(images)}ê°œì˜ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒ ë¡œë“œë¨")
        return images, masks
    
    def train(
        self,
        images: Optional[List[np.ndarray]] = None,
        masks: Optional[List[np.ndarray]] = None,
    ) -> Path:
        """
        StarDist ëª¨ë¸ í•™ìŠµ
        
        Parameters:
            images: ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ì œê³µí•˜ì§€ ì•Šìœ¼ë©´ load_data() í˜¸ì¶œ)
            masks: ë§ˆìŠ¤í¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
        """
        from stardist import fill_label_holes, random_label_cmap
        from stardist.models import Config2D, StarDist2D
        from csbdeep.utils import normalize
        
        # ë°ì´í„° ë¡œë“œ
        if images is None or masks is None:
            images, masks = self.load_data()
        
        # ë ˆì´ë¸” ì •ë¦¬ (êµ¬ë© ì±„ìš°ê¸°)
        print("\nğŸ”§ ë ˆì´ë¸” ì „ì²˜ë¦¬ ì¤‘...")
        masks = [fill_label_holes(mask) for mask in masks]
        
        # í•™ìŠµ/ê²€ì¦ ë¶„í• 
        n_val = max(1, int(len(images) * self.config.validation_split))
        X_train, Y_train = images[:-n_val], masks[:-n_val]
        X_val, Y_val = images[-n_val:], masks[-n_val:]
        
        print(f"   í•™ìŠµ: {len(X_train)}ê°œ, ê²€ì¦: {len(X_val)}ê°œ")
        
        # ëª¨ë¸ ì„¤ì •
        print("\nğŸ—ï¸ ëª¨ë¸ ì„¤ì • ì¤‘...")
        conf = Config2D(
            n_rays=self.config.n_rays,
            grid=self.config.grid,
            n_channel_in=1,
            train_epochs=self.config.epochs,
            train_batch_size=self.config.batch_size,
            train_learning_rate=self.config.learning_rate,
            use_gpu=True,
        )
        print(f"   n_rays: {conf.n_rays}")
        print(f"   grid: {conf.grid}")
        print(f"   epochs: {conf.train_epochs}")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.config.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ ìƒì„±
        model = StarDist2D(
            conf,
            name=self.config.model_name,
            basedir=str(self.config.output_dir),
        )
        
        # ì¦ê°• ì„¤ì •
        augmenter = None
        if self.config.use_augmentation:
            from csbdeep.data import Normalizer, normalize_mi_ma
            
            def simple_augmenter(x, y):
                """ê°„ë‹¨í•œ ë°ì´í„° ì¦ê°• (íšŒì „, í”Œë¦½)"""
                # ëœë¤ íšŒì „ (0, 90, 180, 270ë„)
                k = np.random.randint(0, 4)
                x = np.rot90(x, k)
                y = np.rot90(y, k)
                
                # ëœë¤ ìˆ˜í‰ í”Œë¦½
                if np.random.rand() > 0.5:
                    x = np.fliplr(x)
                    y = np.fliplr(y)
                
                # ëœë¤ ìˆ˜ì§ í”Œë¦½
                if np.random.rand() > 0.5:
                    x = np.flipud(x)
                    y = np.flipud(y)
                
                return x, y
            
            augmenter = simple_augmenter
        
        # í•™ìŠµ
        print(f"\nğŸš€ StarDist í•™ìŠµ ì‹œì‘...")
        print(f"   ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {self.config.output_dir / self.config.model_name}")
        
        # ë°ì´í„°ë¥¼ numpy arrayë¡œ ìŠ¤íƒ (stardist ìš”êµ¬ì‚¬í•­)
        X_train_arr = np.array(X_train)
        Y_train_arr = np.array(Y_train)
        X_val_arr = np.array(X_val)
        Y_val_arr = np.array(Y_val)
        
        # ì±„ë„ ì°¨ì› ì¶”ê°€ (í•„ìš”ì‹œ)
        if X_train_arr.ndim == 3:
            X_train_arr = X_train_arr[..., np.newaxis]
        if X_val_arr.ndim == 3:
            X_val_arr = X_val_arr[..., np.newaxis]
        
        model.train(
            X_train_arr, Y_train_arr,
            validation_data=(X_val_arr, Y_val_arr),
            augmenter=augmenter,
        )
        
        # ì„ê³„ê°’ ìµœì í™”
        print("\nğŸ”§ ì„ê³„ê°’ ìµœì í™” ì¤‘...")
        model.optimize_thresholds(X_val_arr, Y_val_arr)
        
        model_path = self.config.output_dir / self.config.model_name
        print(f"\nâœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"   ëª¨ë¸ ê²½ë¡œ: {model_path}")
        
        return model_path
    
    def get_model_path(self) -> Path:
        """í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ ë°˜í™˜"""
        return self.config.output_dir / self.config.model_name


def create_labeled_data_from_rule_based(
    xqd_files: List[Path],
    output_dir: Path,
    review_with_napari: bool = True,
) -> None:
    """
    Rule-based ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸° ë ˆì´ë¸” ë°ì´í„° ìƒì„±
    
    ì´ í•¨ìˆ˜ëŠ” Rule-based ë°©ë²•ìœ¼ë¡œ ì´ˆê¸° ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ê³ ,
    naparië¡œ ë¦¬ë·°/ìˆ˜ì •í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
    
    Parameters:
        xqd_files: XQD íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (images/, masks/ í•˜ìœ„ í´ë” ìƒì„±)
        review_with_napari: naparië¡œ ë¦¬ë·° ì—¬ë¶€
    
    Example:
        from pathlib import Path
        xqd_files = list(Path("./input_data/xqd").glob("*.xqd"))
        create_labeled_data_from_rule_based(
            xqd_files,
            Path("./labeled_data"),
            review_with_napari=True,
        )
    """
    from grain_analyzer import AFMData, segment_rule_based
    
    images_dir = output_dir / "images"
    masks_dir = output_dir / "masks"
    images_dir.mkdir(parents=True, exist_ok=True)
    masks_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“‚ {len(xqd_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
    
    for xqd_file in xqd_files:
        try:
            # AFM ë°ì´í„° ë¡œë“œ
            data = AFMData(str(xqd_file))
            data.first_correction().second_correction().third_correction()
            data.flat_correction("line_by_line").baseline_correction("min_to_zero")
            
            height = data.get_data()
            meta = data.get_meta_data()
            
            # ì •ê·œí™”
            pmin, pmax = np.percentile(height, [1, 99])
            height_norm = np.clip((height - pmin) / (pmax - pmin), 0, 1).astype(np.float32)
            
            # Rule-based ì„¸ê·¸ë©˜í…Œì´ì…˜
            labels = segment_rule_based(height, meta)
            
            # ì €ì¥
            img_path = images_dir / f"{xqd_file.stem}.npy"
            mask_path = masks_dir / f"{xqd_file.stem}.npy"
            
            np.save(img_path, height_norm)
            np.save(mask_path, labels)
            
            print(f"   âœ“ {xqd_file.name}: {labels.max()} objects")
            
        except Exception as e:
            print(f"   âŒ {xqd_file.name}: {e}")
    
    print(f"\nâœ… ì´ˆê¸° ë ˆì´ë¸” ë°ì´í„° ìƒì„± ì™„ë£Œ: {output_dir}")
    
    if review_with_napari:
        print("\nğŸ“ naparië¡œ ë ˆì´ë¸” ê²€í† /ìˆ˜ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤:")
        print("   pip install napari[all]")
        print("   napari")
        print(f"   - ì´ë¯¸ì§€ í´ë”: {images_dir}")
        print(f"   - ë§ˆìŠ¤í¬ í´ë”: {masks_dir}")
        print("\n   napariì—ì„œ ë§ˆìŠ¤í¬ë¥¼ ìˆ˜ì •í•œ í›„ ê°™ì€ ê²½ë¡œì— ì €ì¥í•˜ì„¸ìš”.")

