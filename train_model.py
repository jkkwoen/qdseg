#!/usr/bin/env python3
"""
QDSeg ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸

AFM quantum dot ë°ì´í„°ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
ì§€ì› ëª¨ë¸: Cellulus (ë¹„ì§€ë„ í•™ìŠµ), StarDist, Cellpose (í–¥í›„ ì§€ì› ì˜ˆì •)

ì‚¬ìš©ë²•:
    # Cellulus ëª¨ë¸ í•™ìŠµ (ê¸°ë³¸)
    python train_model.py
    
    # ì˜µì…˜ ì§€ì •
    python train_model.py --model cellulus --epochs 10000 --batch-size 8
    
    # ì»¤ìŠ¤í…€ ë°ì´í„° ê²½ë¡œ
    python train_model.py --data-dir ./my_data --output-dir ./my_models

ìš”êµ¬ì‚¬í•­:
    pip install torch zarr toml
    
    # Cellulus ê³µì‹ ë²„ì „ (ì„ íƒ):
    pip install git+https://github.com/funkelab/cellulus.git

ì°¸ê³ :
    - CellulusëŠ” ë¹„ì§€ë„ í•™ìŠµ ê¸°ë°˜ìœ¼ë¡œ ë¼ë²¨ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤
    - GPU ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤ (CUDA ë˜ëŠ” MPS)
    - í•™ìŠµëœ ëª¨ë¸ì€ output-dirì— ì €ì¥ë©ë‹ˆë‹¤
"""

import os
import sys
import argparse
import warnings
import platform
import multiprocessing
from pathlib import Path
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, field
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€ (grain_analyzer í´ë”ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬)
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    warnings.warn("python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install python-dotenv'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.", ImportWarning)
    pass


# ============================================================
# ì„¤ì • í´ë˜ìŠ¤
# ============================================================

@dataclass
class TrainingConfig:
    """í•™ìŠµ ì„¤ì •"""
    model_type: str = "cellulus"
    num_epochs: int = 10000
    batch_size: int = 4
    learning_rate: float = 1e-4
    patch_size: int = 128
    num_embeddings: int = 8
    num_fmaps: int = 32
    checkpoint_interval: int = 1000
    log_interval: int = 100
    
    # ê²½ë¡œ
    data_dir: Optional[Path] = None
    output_dir: Optional[Path] = None
    
    # GPU ì„¤ì •
    use_gpu: bool = True
    device: Optional[str] = None
    
    # í•˜ë“œì›¨ì–´ ìµœì í™” ì„¤ì •
    num_workers: int = -1  # -1ì´ë©´ ìë™ ê°ì§€
    prefetch_factor: int = 2
    pin_memory: bool = True
    
    # CUDA ìµœì í™” ì„¤ì •
    use_amp: bool = True  # Automatic Mixed Precision
    cudnn_benchmark: bool = True  # cuDNN ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ
    compile_model: bool = False  # torch.compile (PyTorch 2.0+)
    
    def __post_init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ê²½ë¡œ ì½ê¸°
        if self.data_dir is None:
            env_data_dir = os.getenv('QDSEG_DATA_DIR')
            if env_data_dir:
                self.data_dir = Path(env_data_dir)
            else:
                # ê¸°ë³¸ê°’: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
                project_root = Path(__file__).parent.parent
                self.data_dir = project_root / "tests" / "input_data" / "xqd"
        
        if self.output_dir is None:
            env_output_dir = os.getenv('QDSEG_OUTPUT_DIR')
            if env_output_dir:
                self.output_dir = Path(env_output_dir) / self.model_type
            else:
                # ê¸°ë³¸ê°’: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
                project_root = Path(__file__).parent.parent
                self.output_dir = project_root / "tests" / "model_data" / self.model_type
        
        self.data_dir = Path(self.data_dir)
        self.output_dir = Path(self.output_dir)
        
        # num_workers ìë™ ì„¤ì • (ë””ë°”ì´ìŠ¤ë³„ ìµœì í™”)
        # Apple Silicon MPS: í†µí•© ë©”ëª¨ë¦¬ë¼ num_workers=0ì´ ë” ë¹ ë¦„
        # CUDA: num_workers > 0ì´ íš¨ê³¼ì 
        # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ê¸°ë³¸ê°’ë§Œ ì„¤ì •, ì‹¤ì œ ë””ë°”ì´ìŠ¤ ê°ì§€ í›„ ì¡°ì •ë¨
        if self.num_workers < 0:
            self.num_workers = 0  # ê¸°ë³¸ê°’, ë””ë°”ì´ìŠ¤ ê°ì§€ í›„ ì¡°ì •


# ============================================================
# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ì „ì—­ - multiprocessing pickle í˜¸í™˜)
# ============================================================

class AFMDataset:
    """AFM ì´ë¯¸ì§€ ë°ì´í„°ì…‹ (PyTorch Dataset í˜¸í™˜)"""
    
    def __init__(self, zarr_path, dataset_name='train/raw', patch_size=128):
        import zarr
        root = zarr.open_group(str(zarr_path), mode='r')
        self.data = np.array(root[dataset_name][:])
        self.patch_size = patch_size
        
    def __len__(self):
        return len(self.data) * 16
    
    def __getitem__(self, idx):
        import torch
        img_idx = idx % len(self.data)
        img = self.data[img_idx]
        
        h, w = img.shape
        y = np.random.randint(0, max(1, h - self.patch_size))
        x = np.random.randint(0, max(1, w - self.patch_size))
        
        patch = img[y:y+self.patch_size, x:x+self.patch_size]
        
        if patch.shape[0] < self.patch_size or patch.shape[1] < self.patch_size:
            padded = np.zeros((self.patch_size, self.patch_size), dtype=np.float32)
            padded[:patch.shape[0], :patch.shape[1]] = patch
            patch = padded
        
        return torch.from_numpy(patch).unsqueeze(0)


# ============================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================

def get_hardware_info() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ í•˜ë“œì›¨ì–´ ì •ë³´ ìˆ˜ì§‘"""
    import torch
    
    info = {
        'platform': platform.platform(),
        'processor': platform.processor(),
        'cpu_count': os.cpu_count(),
        'python_version': platform.python_version(),
        'torch_version': torch.__version__,
    }
    
    # ë©”ëª¨ë¦¬ ì •ë³´ (macOS)
    try:
        import subprocess
        result = subprocess.run(
            ['sysctl', '-n', 'hw.memsize'], 
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            mem_bytes = int(result.stdout.strip())
            info['memory_gb'] = mem_bytes / (1024 ** 3)
    except Exception:
        info['memory_gb'] = None
    
    # GPU ì •ë³´
    if torch.cuda.is_available():
        info['gpu_type'] = 'cuda'
        info['gpu_name'] = torch.cuda.get_device_name(0)
        info['gpu_memory_gb'] = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        info['gpu_type'] = 'mps'
        info['gpu_name'] = 'Apple Silicon GPU'
        # MPSëŠ” í†µí•© ë©”ëª¨ë¦¬ ì‚¬ìš©
        info['gpu_memory_gb'] = info.get('memory_gb', 'Unified Memory')
    else:
        info['gpu_type'] = 'cpu'
        info['gpu_name'] = None
        info['gpu_memory_gb'] = None
    
    return info


def print_hardware_info():
    """í•˜ë“œì›¨ì–´ ì •ë³´ ì¶œë ¥"""
    info = get_hardware_info()
    
    print("\nğŸ’» í•˜ë“œì›¨ì–´ ì •ë³´:")
    print(f"   ì‹œìŠ¤í…œ: {info['platform']}")
    print(f"   í”„ë¡œì„¸ì„œ: {info['processor']}")
    print(f"   CPU ì½”ì–´: {info['cpu_count']}ê°œ")
    if info.get('memory_gb'):
        print(f"   ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬: {info['memory_gb']:.1f} GB")
    print(f"   Python: {info['python_version']}")
    print(f"   PyTorch: {info['torch_version']}")
    
    if info['gpu_type'] == 'cuda':
        print(f"   GPU: {info['gpu_name']} ({info['gpu_memory_gb']:.1f} GB)")
    elif info['gpu_type'] == 'mps':
        print(f"   GPU: {info['gpu_name']} (í†µí•© ë©”ëª¨ë¦¬)")
    else:
        print("   GPU: ì‚¬ìš© ë¶ˆê°€")
    
    return info


def get_device(use_gpu: bool = True) -> "torch.device":
    """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
    import torch
    
    if not use_gpu:
        print("   âš ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰")
        return torch.device('cpu')
    
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"   âœ“ CUDA GPU ì‚¬ìš©: {torch.cuda.get_device_name(0)}")
        return device
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device('mps')
        print("   âœ“ Apple Silicon MPS ê°€ì† ì‚¬ìš©")
        return device
    
    print("   âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    return torch.device('cpu')


def setup_environment(config: Optional[TrainingConfig] = None):
    """í™˜ê²½ ì„¤ì • - CUDA/MPS ìµœì í™”"""
    import torch
    
    # macOSì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ë²• ì„¤ì • (fork ëŒ€ì‹  spawn ì‚¬ìš©)
    if platform.system() == 'Darwin':
        try:
            multiprocessing.set_start_method('spawn', force=True)
        except RuntimeError:
            pass  # ì´ë¯¸ ì„¤ì •ëœ ê²½ìš°
    
    # ============================================================
    # CUDA ìµœì í™”
    # ============================================================
    if torch.cuda.is_available():
        # cuDNN ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ - ì…ë ¥ í¬ê¸°ê°€ ì¼ì •í•  ë•Œ ìµœì  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
        if config is None or config.cudnn_benchmark:
            torch.backends.cudnn.benchmark = True
            print("   âœ“ cuDNN benchmark ëª¨ë“œ í™œì„±í™”")
        
        # cuDNN deterministic ëª¨ë“œ (ì¬í˜„ì„± í•„ìš”ì‹œ)
        # torch.backends.cudnn.deterministic = True
        
        # TF32 í™œì„±í™” (Ampere ì´ìƒ GPUì—ì„œ ì„±ëŠ¥ í–¥ìƒ)
        if hasattr(torch.backends.cuda, 'matmul'):
            torch.backends.cuda.matmul.allow_tf32 = True
        if hasattr(torch.backends.cudnn, 'allow_tf32'):
            torch.backends.cudnn.allow_tf32 = True
        
        # CUDA ë©”ëª¨ë¦¬ ê´€ë¦¬
        if os.environ.get('PYTORCH_CUDA_ALLOC_CONF') is None:
            # ë©”ëª¨ë¦¬ ë¶„í•  ìµœì í™”
            os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
    
    # ============================================================
    # MPS ìµœì í™” (Apple Silicon)
    # ============================================================
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        # MPS ë©”ëª¨ë¦¬ ìµœì í™” - í†µí•© ë©”ëª¨ë¦¬ ìµœëŒ€ í™œìš©
        if os.environ.get('PYTORCH_MPS_HIGH_WATERMARK_RATIO') is None:
            os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.9'  # 90%ê¹Œì§€ ì‚¬ìš©
        if os.environ.get('PYTORCH_MPS_LOW_WATERMARK_RATIO') is None:
            os.environ['PYTORCH_MPS_LOW_WATERMARK_RATIO'] = '0.0'
        
        # MPS ì—°ì‚° ìµœì í™”
        if os.environ.get('PYTORCH_ENABLE_MPS_FALLBACK') is None:
            os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'  # ë¯¸ì§€ì› ì—°ì‚°ì€ CPUë¡œ í´ë°±
    
    # ê²½ê³  ìˆ¨ê¹€
    warnings.filterwarnings('ignore', category=DeprecationWarning)
    warnings.filterwarnings('ignore', message='.*MPS.*')
    warnings.filterwarnings('ignore', message='.*beta.*')


def load_jpg_data(data_dir: Path, target_size: int = 512) -> List[np.ndarray]:
    """JPG ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¡œë“œ
    
    Args:
        data_dir: JPG íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        target_size: ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸° (ì •ì‚¬ê°í˜•, ê¸°ë³¸ê°’ 512)
    """
    from skimage import io
    from skimage.transform import resize
    from skimage.color import rgb2gray
    
    jpg_files = sorted(list(data_dir.glob("*.jpg")) + list(data_dir.glob("*.jpeg")) + list(data_dir.glob("*.png")))
    
    if not jpg_files:
        raise FileNotFoundError(f"JPG íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
    
    print(f"\nğŸ“‚ {len(jpg_files)}ê°œì˜ JPG íŒŒì¼ ë°œê²¬")
    
    images = []
    for jpg_file in jpg_files:
        try:
            img = io.imread(str(jpg_file))
            
            # RGB â†’ Grayscale
            if len(img.shape) == 3:
                img = rgb2gray(img)
            
            # Resize
            if img.shape[0] != target_size or img.shape[1] != target_size:
                img = resize(img, (target_size, target_size), 
                            preserve_range=True, anti_aliasing=True)
            
            # Normalize to [0, 1]
            pmin, pmax = np.percentile(img, [1, 99])
            if pmax - pmin > 1e-10:
                img_norm = np.clip((img - pmin) / (pmax - pmin), 0, 1)
            else:
                img_norm = np.zeros_like(img)
            
            # ê°ë§ˆ ë³´ì • (ëŒ€ë¹„ ê°•í™”)
            gamma = 0.7
            img_norm = np.power(img_norm, gamma)
            
            images.append(img_norm.astype(np.float32))
            print(f"   âœ“ {jpg_file.name}: {img.shape}")
        except Exception as e:
            print(f"   âŒ {jpg_file.name}: {e}")
    
    return images


def load_afm_data(data_dir: Path, target_size: int = 512) -> List[np.ndarray]:
    """AFM XQD íŒŒì¼ë“¤ ë¡œë“œ
    
    Args:
        data_dir: XQD íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        target_size: ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸° (ì •ì‚¬ê°í˜•, ê¸°ë³¸ê°’ 512)
    """
    from grain_analyzer import AFMData
    from skimage.transform import resize
    
    xqd_files = sorted(data_dir.glob("*.xqd"))
    
    if not xqd_files:
        raise FileNotFoundError(f"XQD íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
    
    print(f"\nğŸ“‚ {len(xqd_files)}ê°œì˜ XQD íŒŒì¼ ë°œê²¬")
    
    images = []
    for xqd_file in xqd_files:
        try:
            data = AFMData(str(xqd_file))
            data.first_correction().second_correction().third_correction()
            data.flat_correction("line_by_line").baseline_correction("min_to_zero")
            
            height = data.get_data()
            
            # Resize to target size if needed
            if height.shape[0] != target_size or height.shape[1] != target_size:
                height = resize(height, (target_size, target_size), 
                               preserve_range=True, anti_aliasing=True)
            
            # Normalize to [0, 1]
            pmin, pmax = np.percentile(height, [1, 99])
            if pmax - pmin > 1e-10:
                height_norm = np.clip((height - pmin) / (pmax - pmin), 0, 1)
            else:
                height_norm = np.zeros_like(height)
            
            # ê°ë§ˆ ë³´ì • (ëŒ€ë¹„ ê°•í™” - ê²½ê³„ë¥¼ ë” ëª…í™•í•˜ê²Œ)
            gamma = 0.7
            height_norm = np.power(height_norm, gamma)
            
            images.append(height_norm.astype(np.float32))
            print(f"   âœ“ {xqd_file.name}: {height.shape}")
        except Exception as e:
            print(f"   âŒ {xqd_file.name}: {e}")
    
    return images


# ============================================================
# Cellulus í•™ìŠµ
# ============================================================

class CellulusTrainer:
    """Cellulus ëª¨ë¸ í•™ìŠµê¸°"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.device = None
        self.model = None
        self.optimizer = None
        self.scaler = None  # AMP GradScaler
        self.use_amp = False  # AMP ì‚¬ìš© ì—¬ë¶€
        
    def prepare_data(self, images: List[np.ndarray]) -> Path:
        """ë°ì´í„°ë¥¼ Zarr í˜•ì‹ìœ¼ë¡œ ì¤€ë¹„"""
        import zarr
        
        zarr_path = self.config.output_dir / "afm_grains.zarr"
        
        print(f"\nğŸ“¦ Zarr ë°ì´í„°ì…‹ ìƒì„±: {zarr_path}")
        
        stacked = np.stack(images, axis=0).astype(np.float32)
        
        n_train = max(1, len(images) - 2)
        train_data = stacked[:n_train]
        test_data = stacked[n_train:]
        
        root = zarr.open_group(str(zarr_path), mode='w')
        
        try:
            train_group = root.create_group('train')
            test_group = root.create_group('test')
            train_group.create_array('raw', data=train_data, chunks=(1, 256, 256))
            test_group.create_array('raw', data=test_data, chunks=(1, 256, 256))
        except (TypeError, AttributeError):
            root['train/raw'] = train_data
            root['test/raw'] = test_data
        
        print(f"   âœ“ train/raw: {train_data.shape}")
        print(f"   âœ“ test/raw: {test_data.shape}")
        
        return zarr_path
    
    def build_model(self):
        """ëª¨ë¸ êµ¬ì¶•"""
        import torch
        import torch.nn as nn
        
        class SimpleUNet(nn.Module):
            """ê°„ë‹¨í•œ U-Net ê¸°ë°˜ ì„ë² ë”© ë„¤íŠ¸ì›Œí¬"""
            
            def __init__(self, in_channels=1, num_embeddings=8, num_fmaps=32):
                super().__init__()
                
                self.enc1 = self._block(in_channels, num_fmaps)
                self.enc2 = self._block(num_fmaps, num_fmaps * 2)
                self.enc3 = self._block(num_fmaps * 2, num_fmaps * 4)
                
                self.dec2 = self._block(num_fmaps * 4 + num_fmaps * 2, num_fmaps * 2)
                self.dec1 = self._block(num_fmaps * 2 + num_fmaps, num_fmaps)
                
                self.out = nn.Conv2d(num_fmaps, num_embeddings, 1)
                
                self.pool = nn.MaxPool2d(2)
                self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            
            def _block(self, in_ch, out_ch):
                return nn.Sequential(
                    nn.Conv2d(in_ch, out_ch, 3, padding=1),
                    nn.BatchNorm2d(out_ch),
                    nn.ReLU(inplace=True),
                    nn.Conv2d(out_ch, out_ch, 3, padding=1),
                    nn.BatchNorm2d(out_ch),
                    nn.ReLU(inplace=True),
                )
            
            def forward(self, x):
                e1 = self.enc1(x)
                e2 = self.enc2(self.pool(e1))
                e3 = self.enc3(self.pool(e2))
                
                d2 = self.dec2(torch.cat([self.up(e3), e2], dim=1))
                d1 = self.dec1(torch.cat([self.up(d2), e1], dim=1))
                
                return self.out(d1)
        
        self.model = SimpleUNet(
            num_embeddings=self.config.num_embeddings,
            num_fmaps=self.config.num_fmaps,
        ).to(self.device)
        
        self.optimizer = torch.optim.Adam(
            self.model.parameters(), 
            lr=self.config.learning_rate
        )
        
        return self.model
    
    def contrastive_loss(self, embeddings, temperature=0.1):
        """Object-centric contrastive loss"""
        import torch
        import torch.nn.functional as F
        
        b, c, h, w = embeddings.shape
        device = embeddings.device
        
        embeddings = F.normalize(embeddings, dim=1)
        
        num_anchors = min(256, h * w)
        indices = torch.randperm(h * w, device=device)[:num_anchors]
        
        embeddings_flat = embeddings.view(b, c, -1)
        anchors = embeddings_flat[:, :, indices]
        
        similarity = torch.bmm(anchors.transpose(1, 2), embeddings_flat) / temperature
        
        anchor_y = indices // w
        anchor_x = indices % w
        all_y = torch.arange(h, device=device).view(-1, 1).expand(h, w).reshape(-1)
        all_x = torch.arange(w, device=device).view(1, -1).expand(h, w).reshape(-1)
        
        dist = ((anchor_y.view(-1, 1) - all_y.view(1, -1)) ** 2 + 
                (anchor_x.view(-1, 1) - all_x.view(1, -1)) ** 2).float().sqrt()
        
        positive_mask = (dist < 5).float()
        negative_mask = (dist > 20).float()
        
        exp_sim = torch.exp(similarity)
        
        positive_sim = (exp_sim * positive_mask.unsqueeze(0)).sum(dim=-1)
        negative_sim = (exp_sim * negative_mask.unsqueeze(0)).sum(dim=-1)
        
        loss = -torch.log(positive_sim / (positive_sim + negative_sim + 1e-10) + 1e-10)
        
        return loss.mean()
    
    def train(self, zarr_path: Path):
        """ëª¨ë¸ í•™ìŠµ"""
        import torch
        from torch.utils.data import DataLoader
        from tqdm import tqdm
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = get_device(self.config.use_gpu)
        
        # ============================================================
        # AMP (Automatic Mixed Precision) ì„¤ì •
        # ============================================================
        self.use_amp = False
        self.scaler = None
        
        if self.config.use_amp:
            if self.device.type == 'cuda':
                # CUDA AMP - FP16 ì‚¬ìš©
                self.use_amp = True
                self.scaler = torch.cuda.amp.GradScaler()
                print("   âœ“ CUDA AMP (FP16) í™œì„±í™”")
            elif self.device.type == 'mps':
                # MPSì—ì„œëŠ” AMP ì œí•œì  ì§€ì›
                # PyTorch 2.0+ ì—ì„œ ì¼ë¶€ ì§€ì›
                try:
                    # MPSì—ì„œ autocast í…ŒìŠ¤íŠ¸
                    with torch.autocast(device_type='mps', dtype=torch.float16):
                        pass
                    self.use_amp = True
                    print("   âœ“ MPS AMP í™œì„±í™”")
                except Exception:
                    self.use_amp = False
                    print("   âš ï¸ MPS AMP ë¯¸ì§€ì› - FP32 ì‚¬ìš©")
        
        # ëª¨ë¸ êµ¬ì¶•
        self.build_model()
        
        # ============================================================
        # torch.compile (PyTorch 2.0+) - ì¶”ê°€ ìµœì í™”
        # ============================================================
        if self.config.compile_model and hasattr(torch, 'compile'):
            try:
                self.model = torch.compile(self.model)
                print("   âœ“ torch.compile ì ìš©")
            except Exception as e:
                print(f"   âš ï¸ torch.compile ì‹¤íŒ¨: {e}")
        
        # ë°ì´í„°ë¡œë” - ë©€í‹°ì½”ì–´ CPU í™œìš©
        dataset = AFMDataset(zarr_path, patch_size=self.config.patch_size)
        
        # ============================================================
        # ë””ë°”ì´ìŠ¤ë³„ DataLoader ìµœì í™”
        # ============================================================
        num_workers = self.config.num_workers
        pin_memory = self.config.pin_memory
        prefetch_factor = self.config.prefetch_factor
        
        # Apple Silicon MPS ìµœì í™”
        # - í†µí•© ë©”ëª¨ë¦¬: pin_memory ë¶ˆí•„ìš”
        # - ë©”ì¸ í”„ë¡œì„¸ìŠ¤ ë¡œë”©ì´ ë” ë¹ ë¦„ (í”„ë¡œì„¸ìŠ¤ê°„ ë³µì‚¬ ì˜¤ë²„í—¤ë“œ ì—†ìŒ)
        if self.device.type == 'mps':
            num_workers = 0  # MPSì—ì„œëŠ” ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ê°€ ë” ë¹ ë¦„
            pin_memory = False
            print("   âœ“ MPS ìµœì í™”: num_workers=0 (í†µí•© ë©”ëª¨ë¦¬)")
        
        # CUDA ìµœì í™”
        elif self.device.type == 'cuda':
            if num_workers == 0:
                cpu_count = os.cpu_count() or 4
                num_workers = min(cpu_count // 2, 8)
            pin_memory = True
            print(f"   âœ“ CUDA ìµœì í™”: num_workers={num_workers}, pin_memory=True")
        
        persistent_workers = num_workers > 0
        
        print(f"\nâš¡ DataLoader ì„¤ì •:")
        print(f"   num_workers: {num_workers}")
        print(f"   pin_memory: {pin_memory}")
        
        dataloader_kwargs = {
            'batch_size': self.config.batch_size,
            'shuffle': True,
            'num_workers': num_workers,
            'pin_memory': pin_memory,
        }
        
        # num_workers > 0ì¼ ë•Œë§Œ ì¶”ê°€ ì˜µì…˜ ì ìš©
        if num_workers > 0:
            dataloader_kwargs['prefetch_factor'] = prefetch_factor
            dataloader_kwargs['persistent_workers'] = persistent_workers
        
        dataloader = DataLoader(dataset, **dataloader_kwargs)
        
        print(f"\nğŸš€ í•™ìŠµ ì‹œì‘: {self.config.num_epochs} epochs, batch_size={self.config.batch_size}\n")
        
        best_loss = float('inf')
        checkpoint_path = self.config.output_dir / 'best_loss.pth'
        
        # tqdm ì§„í–‰ í‘œì‹œì¤„
        epoch_pbar = tqdm(
            range(self.config.num_epochs),
            desc="Training",
            unit="epoch",
            ncols=100,
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
        )
        
        for epoch in epoch_pbar:
            self.model.train()
            total_loss = 0
            
            # ë°°ì¹˜ë³„ ì§„í–‰ í‘œì‹œ (ì—í­ ë‚´)
            batch_pbar = tqdm(
                dataloader,
                desc=f"  Epoch {epoch+1}",
                leave=False,
                ncols=80,
                bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt}'
            )
            
            for batch in batch_pbar:
                batch = batch.to(self.device, non_blocking=True)
                
                self.optimizer.zero_grad(set_to_none=True)  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
                
                # AMP ì ìš©
                if self.use_amp and self.device.type == 'cuda':
                    with torch.cuda.amp.autocast():
                        embeddings = self.model(batch)
                        loss = self.contrastive_loss(embeddings)
                    self.scaler.scale(loss).backward()
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                elif self.use_amp and self.device.type == 'mps':
                    with torch.autocast(device_type='mps', dtype=torch.float16):
                        embeddings = self.model(batch)
                        loss = self.contrastive_loss(embeddings)
                    loss.backward()
                    self.optimizer.step()
                else:
                    embeddings = self.model(batch)
                    loss = self.contrastive_loss(embeddings)
                    loss.backward()
                    self.optimizer.step()
                
                total_loss += loss.item()
            
            avg_loss = total_loss / len(dataloader)
            
            # ì§„í–‰ í‘œì‹œì¤„ ì—…ë°ì´íŠ¸
            epoch_pbar.set_postfix({
                'loss': f'{avg_loss:.4f}',
                'best': f'{best_loss:.4f}'
            })
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if avg_loss < best_loss:
                best_loss = avg_loss
                torch.save({
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'epoch': epoch,
                    'loss': avg_loss,
                    'config': {
                        'num_embeddings': self.config.num_embeddings,
                        'num_fmaps': self.config.num_fmaps,
                    }
                }, checkpoint_path)
                # ì§„í–‰ í‘œì‹œì¤„ ì—…ë°ì´íŠ¸
                epoch_pbar.set_postfix({
                    'loss': f'{avg_loss:.4f}',
                    'best': f'{best_loss:.4f}',
                    'saved': 'âœ“'
                })
            
            # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸
            if (epoch + 1) % self.config.checkpoint_interval == 0:
                periodic_path = self.config.output_dir / f'checkpoint_epoch_{epoch+1}.pth'
                torch.save({
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'epoch': epoch,
                    'loss': avg_loss,
                }, periodic_path)
                tqdm.write(f"   ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {periodic_path.name}")
        
        epoch_pbar.close()
        print(f"\nâœ“ í•™ìŠµ ì™„ë£Œ! Best loss: {best_loss:.4f}")
        print(f"âœ“ ëª¨ë¸ ì €ì¥ë¨: {checkpoint_path}")
        
        return checkpoint_path


# ============================================================
# í–¥í›„ í™•ì¥ìš© Trainer í´ë˜ìŠ¤ë“¤
# ============================================================

class StarDistTrainer:
    """StarDist ëª¨ë¸ í•™ìŠµê¸° (í–¥í›„ êµ¬í˜„)"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
    
    def train(self, images: List[np.ndarray], labels: List[np.ndarray]):
        """
        StarDist í•™ìŠµ (ë¼ë²¨ í•„ìš”)
        
        TODO: StarDist ì»¤ìŠ¤í…€ í•™ìŠµ êµ¬í˜„
        """
        raise NotImplementedError(
            "StarDist ì»¤ìŠ¤í…€ í•™ìŠµì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "ì°¸ê³ : https://github.com/stardist/stardist"
        )


class CellposeTrainer:
    """Cellpose ëª¨ë¸ í•™ìŠµê¸° (í–¥í›„ êµ¬í˜„)"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
    
    def train(self, images: List[np.ndarray], labels: List[np.ndarray]):
        """
        Cellpose í•™ìŠµ (ë¼ë²¨ í•„ìš”)
        
        TODO: Cellpose ì»¤ìŠ¤í…€ í•™ìŠµ êµ¬í˜„
        """
        raise NotImplementedError(
            "Cellpose ì»¤ìŠ¤í…€ í•™ìŠµì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "ì°¸ê³ : https://github.com/MouseLand/cellpose"
        )


# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def get_trainer(config: TrainingConfig):
    """ì„¤ì •ì— ë§ëŠ” Trainer ë°˜í™˜"""
    trainers = {
        'cellulus': CellulusTrainer,
        'stardist': StarDistTrainer,
        'cellpose': CellposeTrainer,
    }
    
    if config.model_type not in trainers:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {config.model_type}\n"
                        f"ì§€ì› ëª¨ë¸: {list(trainers.keys())}")
    
    return trainers[config.model_type](config)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='QDSeg ëª¨ë¸ í•™ìŠµ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ê¸°ë³¸ Cellulus í•™ìŠµ
  python train_model.py
  
  # ì—í­ ìˆ˜ ì§€ì •
  python train_model.py --epochs 5000
  
  # ì»¤ìŠ¤í…€ ê²½ë¡œ
  python train_model.py --data-dir ./my_data --output-dir ./my_models
  
  # ë°°ì¹˜ í¬ê¸° ë° í•™ìŠµë¥  ì¡°ì •
  python train_model.py --batch-size 8 --lr 0.0005
"""
    )
    
    # ëª¨ë¸ ì„¤ì •
    parser.add_argument('--model', type=str, default='cellulus',
                        choices=['cellulus', 'stardist', 'cellpose'],
                        help='í•™ìŠµí•  ëª¨ë¸ íƒ€ì… (ê¸°ë³¸: cellulus)')
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    parser.add_argument('--epochs', type=int, default=10000,
                        help='í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸: 10000)')
    parser.add_argument('--batch-size', type=int, default=4,
                        help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 4)')
    parser.add_argument('--lr', type=float, default=1e-4,
                        help='í•™ìŠµë¥  (ê¸°ë³¸: 0.0001)')
    parser.add_argument('--patch-size', type=int, default=128,
                        help='í•™ìŠµ íŒ¨ì¹˜ í¬ê¸° (ê¸°ë³¸: 128)')
    
    # ëª¨ë¸ êµ¬ì¡°
    parser.add_argument('--num-embeddings', type=int, default=8,
                        help='ì„ë² ë”© ì±„ë„ ìˆ˜ (ê¸°ë³¸: 8)')
    parser.add_argument('--num-fmaps', type=int, default=32,
                        help='ê¸°ë³¸ íŠ¹ì„± ë§µ ìˆ˜ (ê¸°ë³¸: 32)')
    
    # ê²½ë¡œ
    parser.add_argument('--data-dir', type=str, default=None,
                        help='í•™ìŠµ ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸: $QDSEG_DATA_DIR ë˜ëŠ” tests/input_data/xqd)')
    parser.add_argument('--output-dir', type=str, default=None,
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: $QDSEG_OUTPUT_DIR/{model} ë˜ëŠ” tests/model_data/{model})')
    
    # GPU ì„¤ì •
    parser.add_argument('--no-gpu', action='store_true',
                        help='GPU ì‚¬ìš© ë¹„í™œì„±í™”')
    parser.add_argument('--device', type=str, default=None,
                        help='íŠ¹ì • ë””ë°”ì´ìŠ¤ ì§€ì • (cuda, mps, cpu)')
    
    # ì²´í¬í¬ì¸íŠ¸
    parser.add_argument('--checkpoint-interval', type=int, default=1000,
                        help='ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê°„ê²© (ê¸°ë³¸: 1000)')
    parser.add_argument('--log-interval', type=int, default=100,
                        help='ë¡œê·¸ ì¶œë ¥ ê°„ê²© (ê¸°ë³¸: 100)')
    
    # í•˜ë“œì›¨ì–´ ìµœì í™”
    parser.add_argument('--num-workers', type=int, default=-1,
                        help='DataLoader ì›Œì»¤ ìˆ˜ (-1: ìë™, 0: ë¹„í™œì„±í™”)')
    parser.add_argument('--prefetch-factor', type=int, default=2,
                        help='ë¯¸ë¦¬ ë¡œë“œí•  ë°°ì¹˜ ìˆ˜ (ê¸°ë³¸: 2)')
    parser.add_argument('--no-pin-memory', action='store_true',
                        help='pin_memory ë¹„í™œì„±í™”')
    
    # CUDA/GPU ìµœì í™”
    parser.add_argument('--no-amp', action='store_true',
                        help='Automatic Mixed Precision ë¹„í™œì„±í™”')
    parser.add_argument('--no-cudnn-benchmark', action='store_true',
                        help='cuDNN benchmark ëª¨ë“œ ë¹„í™œì„±í™”')
    parser.add_argument('--compile', action='store_true',
                        help='torch.compile ì‚¬ìš© (PyTorch 2.0+)')
    
    args = parser.parse_args()
    
    # ì„¤ì • ìƒì„±
    config = TrainingConfig(
        model_type=args.model,
        num_epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.lr,
        patch_size=args.patch_size,
        num_embeddings=args.num_embeddings,
        num_fmaps=args.num_fmaps,
        data_dir=Path(args.data_dir) if args.data_dir else None,
        output_dir=Path(args.output_dir) if args.output_dir else None,
        use_gpu=not args.no_gpu,
        device=args.device,
        checkpoint_interval=args.checkpoint_interval,
        log_interval=args.log_interval,
        num_workers=args.num_workers,
        prefetch_factor=args.prefetch_factor,
        pin_memory=not args.no_pin_memory,
        use_amp=not args.no_amp,
        cudnn_benchmark=not args.no_cudnn_benchmark,
        compile_model=args.compile,
    )
    
    # í™˜ê²½ ì„¤ì •
    setup_environment(config)
    
    # í—¤ë” ì¶œë ¥
    print("=" * 70)
    print(f"ğŸ§  QDSeg ëª¨ë¸ í•™ìŠµ: {config.model_type.upper()}")
    print("=" * 70)
    
    # í•˜ë“œì›¨ì–´ ì •ë³´ ì¶œë ¥
    hw_info = print_hardware_info()
    
    print(f"\nğŸ“‹ í•™ìŠµ ì„¤ì •:")
    print(f"   ëª¨ë¸: {config.model_type}")
    print(f"   ì—í­: {config.num_epochs}")
    print(f"   ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
    print(f"   í•™ìŠµë¥ : {config.learning_rate}")
    print(f"   DataLoader ì›Œì»¤: {config.num_workers}")
    print(f"   ë°ì´í„°: {config.data_dir}")
    print(f"   ì¶œë ¥: {config.output_dir}")
    
    # M3 Ultra ìµœì í™” ê¶Œì¥ì‚¬í•­
    if hw_info.get('cpu_count', 0) >= 20 and hw_info.get('memory_gb', 0) >= 64:
        print(f"\nğŸ’¡ ê³ ì„±ëŠ¥ í•˜ë“œì›¨ì–´ ê°ì§€! ê¶Œì¥ ì„¤ì •:")
        print(f"   --batch-size 16 ë˜ëŠ” 32 (í˜„ì¬: {config.batch_size})")
        print(f"   --num-workers 8~12 (í˜„ì¬: {config.num_workers})")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    config.output_dir.mkdir(parents=True, exist_ok=True)
    
    # ë°ì´í„° ë¡œë“œ
    print("\n" + "=" * 70)
    print("1ï¸âƒ£  ë°ì´í„° ë¡œë“œ")
    print("=" * 70)
    
    images = load_afm_data(config.data_dir)
    
    if not images:
        print("âŒ ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 1
    
    # Trainer ìƒì„± ë° í•™ìŠµ
    print("\n" + "=" * 70)
    print(f"2ï¸âƒ£  {config.model_type.upper()} ëª¨ë¸ í•™ìŠµ")
    print("=" * 70)
    
    trainer = get_trainer(config)
    
    if config.model_type == 'cellulus':
        zarr_path = trainer.prepare_data(images)
        checkpoint_path = trainer.train(zarr_path)
    else:
        # StarDist, CellposeëŠ” ë¼ë²¨ì´ í•„ìš”
        trainer.train(images, labels=None)
        checkpoint_path = None
    
    # ì™„ë£Œ
    print("\n" + "=" * 70)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    print("=" * 70)
    
    if checkpoint_path and checkpoint_path.exists():
        print(f"\nâœ“ í•™ìŠµëœ ëª¨ë¸: {checkpoint_path}")
        print("\nì‚¬ìš© ë°©ë²•:")
        print("   from qdseg import segment_cellulus")
        print(f"   labels = segment_cellulus(height, checkpoint_path='{checkpoint_path}')")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

